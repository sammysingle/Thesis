{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1yU8CMX1cx3J0Zb6ITdRDHzdn-X1_hO_N",
      "authorship_tag": "ABX9TyN5wp1nFMwxTHo/Bc9nKPxY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sammysingle/Thesis/blob/main/ColabWorkspaces/thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG-16"
      ],
      "metadata": {
        "id": "HV8gSNxyxejp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Original Dataset*"
      ],
      "metadata": {
        "id": "XAyPTfUTxnf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# ------------------------------ Build VGG-16 ------------------------------ #\n",
        "# Create base VGG-16 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = VGG16(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of VGG16\n",
        "# Global average pooling\n",
        "global_average_pooling = GlobalAveragePooling2D()\n",
        "# Fully connected layer 1: 4096 neurons ReLU activation function\n",
        "fc1 = Dense(units = 4096, activation = 'relu')\n",
        "# Fully connected layer 2: 4096 neurons ReLU activation function\n",
        "fc2 = Dense(units = 4096, activation = 'relu')\n",
        "# Classification layer: softmax layer with 8 neurons for class labels\n",
        "classifier = Dense(units = 8, activation = 'softmax')\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of VGG-16\n",
        "model = global_average_pooling(model) # Global average pooling layer\n",
        "model = fc1(model)                    # Fully connected layer: 4096 neuron ReLU\n",
        "model = fc2(model)                    # Fully connected layer: 4096 neuron ReLU\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build VGG-16 model\n",
        "vgg16 = Model(inputs, outputs, name = 'VGG-16')\n",
        "\n",
        "# ------------------------------ Train VGG-16 ------------------------------ #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "vgg16.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/VGG-16/Original Training/vgg16-original-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "vgg16.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "Yw1LnUnixt9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf20712c-bb4e-45e7-847d-3c8deecd4dd8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Found 2433 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "609/609 [==============================] - 86s 123ms/step - loss: 1.2791 - accuracy: 0.4969 - precision: 0.7419 - recall: 0.3202 - val_loss: 0.9874 - val_accuracy: 0.6029 - val_precision: 0.7281 - val_recall: 0.4662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbaa460a90>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Augmented Dataset*"
      ],
      "metadata": {
        "id": "94OQMZJ8xqx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# ------------------------------ Build VGG-16 ------------------------------ #\n",
        "# Create base VGG-16 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = VGG16(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of VGG16\n",
        "# Global average pooling\n",
        "global_average_pooling = GlobalAveragePooling2D()\n",
        "# Fully connected layer 1: 4096 neurons ReLU activation function\n",
        "fc1 = Dense(units = 4096, activation = 'relu')\n",
        "# Fully connected layer 2: 4096 neurons ReLU activation function\n",
        "fc2 = Dense(units = 4096, activation = 'relu')\n",
        "# Classification layer: softmax layer with 8 neurons for class labels\n",
        "classifier = Dense(units = 8, activation = 'softmax')\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of VGG-16\n",
        "model = global_average_pooling(model) # Global average pooling layer\n",
        "model = fc1(model)                    # Fully connected layer: 4096 neuron ReLU\n",
        "model = fc2(model)                    # Fully connected layer: 4096 neuron ReLU\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build VGG-16 model\n",
        "vgg16 = Model(inputs, outputs, name = 'VGG-16')\n",
        "\n",
        "# ------------------------------ Train VGG-16 ------------------------------ #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Augmented Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "vgg16.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/VGG-16/Augmented Training/vgg16-augmented-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "vgg16.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "5rg9zGqBxuXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeacc0fd-b48b-4d5d-d4ba-74eef7344e7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10083 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "2521/2521 [==============================] - 221s 87ms/step - loss: 1.1059 - accuracy: 0.5847 - precision_1: 0.7688 - recall_1: 0.4278 - val_loss: 0.7128 - val_accuracy: 0.7439 - val_precision_1: 0.8488 - val_recall_1: 0.6302\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb7c0464d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet-50"
      ],
      "metadata": {
        "id": "53p5XLdexwen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Original Dataset*"
      ],
      "metadata": {
        "id": "RrNMVKJHx4Qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# ----------------------------- Build ResNet-50 ---------------------------- #\n",
        "# Create base ResNet-50 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = ResNet50(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of ResNet-50\n",
        "global_average_pool = GlobalAveragePooling2D()        # Global average pooling\n",
        "classifier = Dense(units = 8, activation = 'softmax') # Softmax classifier\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of ResNet-50\n",
        "model = global_average_pool(model)    # Global average pooling layer\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build res_net_50 model\n",
        "res_net_50 = Model(inputs, outputs, name = 'ResNet-50')\n",
        "\n",
        "# ----------------------------- Train ResNet-50 ---------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "res_net_50.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/ResNet-50/Original Training/resnet50-original-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "res_net_50.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "PNURmEnEx4Zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6d57cc-9a36-4323-b968-8f2c0c223594"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n",
            "Found 2433 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "609/609 [==============================] - 26s 20ms/step - loss: 2.0350 - accuracy: 0.2035 - precision_2: 0.7143 - recall_2: 0.0082 - val_loss: 1.9462 - val_accuracy: 0.1899 - val_precision_2: 0.5000 - val_recall_2: 0.0144\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb59f9b3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Augmented Dataset*"
      ],
      "metadata": {
        "id": "SfrH0rh1x4fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# ----------------------------- Build ResNet-50 ---------------------------- #\n",
        "# Create base ResNet-50 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = ResNet50(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of ResNet-50\n",
        "global_average_pool = GlobalAveragePooling2D()        # Global average pooling\n",
        "classifier = Dense(units = 8, activation = 'softmax') # Softmax classifier\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of ResNet-50\n",
        "model = global_average_pool(model)    # Global average pooling layer\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build res_net_50 model\n",
        "res_net_50 = Model(inputs, outputs, name = 'ResNet-50')\n",
        "\n",
        "# ----------------------------- Train ResNet-50 ---------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Augmented Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "res_net_50.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/ResNet-50/Augmented Training/resnet50-augmented-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "res_net_50.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "hLXm5f3Gx4lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0a23e6-d9ba-4dab-9ba1-34b1e51d7444"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10083 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "2521/2521 [==============================] - 41s 15ms/step - loss: 1.9537 - accuracy: 0.2447 - precision_3: 0.7170 - recall_3: 0.0221 - val_loss: 1.7984 - val_accuracy: 0.3799 - val_precision_3: 0.6154 - val_recall_3: 0.0230\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb592a7fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DenseNet121"
      ],
      "metadata": {
        "id": "sdG_JzLPyESP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Original Dataset*"
      ],
      "metadata": {
        "id": "Hp2r4QICyTgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# --------------------------- Build DenseNet121 ---------------------------- #\n",
        "# Create base DenseNet121 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = DenseNet121(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of DenseNet121\n",
        "# 7x7 global average pooling layer\n",
        "global_average_pooling = GlobalAveragePooling2D()\n",
        "# Fully connected layer using softmax activation function for 8 labels\n",
        "classifier = Dense(units = 8, activation = 'softmax')\n",
        "\n",
        "# Connect input layer, base model and output classifier\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of DenseNet121\n",
        "model = global_average_pooling(model) # Fully connected layer: 7x7 global average pooling\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build DenseNet121 model\n",
        "dense_net_121 = Model(inputs, outputs, name = 'DenseNet121')\n",
        "\n",
        "# --------------------------- Train DenseNet121 ---------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "dense_net_121.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/DenseNet121/Original Training/densenet121-original-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "dense_net_121.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "D5W_qLovyWva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e7204ba-750c-4247-e8fd-0418631a5761"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "29097984/29084464 [==============================] - 0s 0us/step\n",
            "Found 2433 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "609/609 [==============================] - 32s 34ms/step - loss: 0.8754 - accuracy: 0.6987 - precision_4: 0.8348 - recall_4: 0.5586 - val_loss: 0.5600 - val_accuracy: 0.7914 - val_precision_4: 0.8479 - val_recall_4: 0.7137\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb547c85d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Augmented Dataset*"
      ],
      "metadata": {
        "id": "P7bkI9VO0sx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# --------------------------- Build DenseNet121 ---------------------------- #\n",
        "# Create base DenseNet121 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = DenseNet121(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of DenseNet121\n",
        "# 7x7 global average pooling layer\n",
        "global_average_pooling = GlobalAveragePooling2D()\n",
        "# Fully connected layer using softmax activation function for 8 labels\n",
        "classifier = Dense(units = 8, activation = 'softmax')\n",
        "\n",
        "# Connect input layer, base model and output classifier\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of DenseNet121\n",
        "model = global_average_pooling(model) # Fully connected layer: 7x7 global average pooling\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build DenseNet121 model\n",
        "dense_net_121 = Model(inputs, outputs, name = 'DenseNet121')\n",
        "\n",
        "# --------------------------- Train DenseNet121 ---------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Augmented Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "dense_net_121.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/DenseNet121/Augmented Training/densenet121-augmented-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "dense_net_121.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "nT16d9Dv0vOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e25b5f-fb1e-4e3d-897f-6d30f936fe54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10083 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "2521/2521 [==============================] - 69s 25ms/step - loss: 0.7161 - accuracy: 0.7424 - precision_5: 0.8460 - recall_5: 0.6560 - val_loss: 0.4631 - val_accuracy: 0.8388 - val_precision_5: 0.8824 - val_recall_5: 0.8101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb52ceb1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inception V3"
      ],
      "metadata": {
        "id": "k7P0fWWJ4-qj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Original Dataset*"
      ],
      "metadata": {
        "id": "ZcLZ2gZJ5CxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# ---------------------------- Build InceptionV3 --------------------------- #\n",
        "# Create base InceptionV3 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = InceptionV3(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of InceptionV3\n",
        "global_average_pool = GlobalAveragePooling2D()        # global average pooling\n",
        "fc1 = Dense(units = 2048, activation = 'relu')        # 2048 neuron fully connected layer with ReLU activation\n",
        "classifier = Dense(units = 8, activation = 'softmax') # Softmax classifier\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of InceptionV3\n",
        "model = global_average_pool(model)    # Global average pooling layer\n",
        "model = fc1(model)                    # Fully connected layer: 2048 neuron ReLU\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build inception_v3 model\n",
        "inception_v3 = Model(inputs, outputs, name = 'InceptionV3')\n",
        "\n",
        "# ---------------------------- Train InceptionV3 -------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "inception_v3.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/InceptionV3/Original Training/inceptionv3-original-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "inception_v3.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "KuSDhW3b5FhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769a09bf-99b7-412a-d6a1-4a44285d236e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "87924736/87910968 [==============================] - 0s 0us/step\n",
            "Found 2433 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "609/609 [==============================] - 26s 30ms/step - loss: 0.9911 - accuracy: 0.7074 - precision_6: 0.7735 - recall_6: 0.6498 - val_loss: 0.5797 - val_accuracy: 0.7871 - val_precision_6: 0.8389 - val_recall_6: 0.7266\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb52da8ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Augmented Dataset*"
      ],
      "metadata": {
        "id": "A-5dimh75Fwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# ---------------------------- Build InceptionV3 --------------------------- #\n",
        "# Create base InceptionV3 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = InceptionV3(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of InceptionV3\n",
        "global_average_pool = GlobalAveragePooling2D()        # global average pooling\n",
        "fc1 = Dense(units = 2048, activation = 'relu')        # 2048 neuron fully connected layer with ReLU activation\n",
        "classifier = Dense(units = 8, activation = 'softmax') # Softmax classifier\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of InceptionV3\n",
        "model = global_average_pool(model)    # Global average pooling layer\n",
        "model = fc1(model)                    # Fully connected layer: 2048 neuron ReLU\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build inception_v3 model\n",
        "inception_v3 = Model(inputs, outputs, name = 'InceptionV3')\n",
        "\n",
        "# ---------------------------- Train InceptionV3 -------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Augmented Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "inception_v3.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/InceptionV3/Augmented Training/inceptionv3-augmented-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "inception_v3.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "aUdadcsB5Hkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910ee308-089b-49c4-94d9-dc189a77bb9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10083 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "2521/2521 [==============================] - 59s 22ms/step - loss: 0.7620 - accuracy: 0.7425 - precision_7: 0.8070 - recall_7: 0.6871 - val_loss: 0.4869 - val_accuracy: 0.8288 - val_precision_7: 0.8814 - val_recall_7: 0.7914\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb998102110>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNet V2"
      ],
      "metadata": {
        "id": "ZIJ6fCbh5INc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Original Dataset*"
      ],
      "metadata": {
        "id": "tfe3hDgr5Llh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# ---------------------------- Build MobileNetV2 --------------------------- #\n",
        "# Create base MobileNetV2 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = MobileNetV2(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of InceptionV3\n",
        "global_average_pool = GlobalAveragePooling2D()        # global average pooling\n",
        "classifier = Dense(units = 8, activation = 'softmax') # 1000 neuron fully connected layer with ReLU activation\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of InceptionV3\n",
        "model = global_average_pool(model)    # Global average pooling layer\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build inception_v3 model\n",
        "mobile_net_v2 = Model(inputs, outputs, name = 'MobileNetV2')\n",
        "\n",
        "# ---------------------------- Train MobileNetV2 -------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "mobile_net_v2.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/MobileNetV2/Original Training/mobilenetv2-original-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "mobile_net_v2.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "lFr7fNHG5WGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbae5eeb-60a5-4ac5-ccaf-7b1a7be2d3f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "Found 2433 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "609/609 [==============================] - 15s 15ms/step - loss: 0.7588 - accuracy: 0.7365 - precision_8: 0.8412 - recall_8: 0.6379 - val_loss: 0.5048 - val_accuracy: 0.8173 - val_precision_8: 0.8558 - val_recall_8: 0.7683\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb995d31c10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Augmented Dataset*"
      ],
      "metadata": {
        "id": "GrZgwPcG5WMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os library to navigate directories\n",
        "import os\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "\n",
        "# ---------------------------- Build MobileNetV2 --------------------------- #\n",
        "# Create base MobileNetV2 model:\n",
        "  # 224x224x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = MobileNetV2(input_shape = (224, 224, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of InceptionV3\n",
        "global_average_pool = GlobalAveragePooling2D()        # global average pooling\n",
        "classifier = Dense(units = 8, activation = 'softmax') # 1000 neuron fully connected layer with ReLU activation\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (224, 224, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)            # Feature extraction layers of InceptionV3\n",
        "model = global_average_pool(model)    # Global average pooling layer\n",
        "outputs = classifier(model)           # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build inception_v3 model\n",
        "mobile_net_v2 = Model(inputs, outputs, name = 'MobileNetV2')\n",
        "\n",
        "# ---------------------------- Train MobileNetV2 -------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4   # Batch size for gradient learning\n",
        "img_height = 224 # Image pixel height\n",
        "img_width = 224  # Image pixel width\n",
        "epochs = 100     # 100 rounds of training\n",
        "\n",
        "# Define training and validation directory paths\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Augmented Training Dataset'\n",
        "validation_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset'\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "mobile_net_v2.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/MobileNetV2/Augmented Training/mobilenetv2-augmented-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = False, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "mobile_net_v2.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "Nwy6Ikt95Yso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6571428-dbbc-471e-fa15-35d90c1b9fdc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10083 files belonging to 8 classes.\n",
            "Found 695 files belonging to 8 classes.\n",
            "2521/2521 [==============================] - 32s 12ms/step - loss: 0.6705 - accuracy: 0.7614 - precision_9: 0.8301 - recall_9: 0.6965 - val_loss: 0.4920 - val_accuracy: 0.8288 - val_precision_9: 0.8561 - val_recall_9: 0.8129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb99706d090>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing"
      ],
      "metadata": {
        "id": "1DLcJb4pZeJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import directory navigation\n",
        "from os import listdir\n",
        "# Import tensorflow libraries for loading models and testing dataset\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "# Constants for model file paths\n",
        "base_model_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/'\n",
        "models = ['VGG-16', 'ResNet-50', 'DenseNet121', 'InceptionV3', 'MobileNetV2']\n",
        "\n",
        "# ------------------------- Dataset and Testing Functions ------------------------ #\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "def test_model(test_ds, model_path):\n",
        "    # Get directory of models\n",
        "    directory = listdir(model_path)\n",
        "    # Loop through models and test\n",
        "    for file in directory:\n",
        "        print('Model: '+ file)\n",
        "        model = load_model(model_path+'/'+file)\n",
        "        loss, accuracy, precision, recall = model.evaluate(test_ds)\n",
        "        print('Accuracy: ' + str(accuracy))\n",
        "        print('Precision: ' + str(precision))\n",
        "        print('Recall: ' + str(recall)+'\\n')\n",
        "\n",
        "# ----------------------------- Load Testing Dataset ----------------------------- #\n",
        "# Define testing dataset\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Testing Dataset'\n",
        "test_ds = image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (224, 224),\n",
        "    batch_size = 346,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize testing pixel values\n",
        "test_ds = test_ds.map(process)\n",
        "\n",
        "# ----------------------------- Load and Test Models ----------------------------- #\n",
        "for model in models:\n",
        "    print('\\n# ---------------------------------------- '+model+' ---------------------------------------- #\\n')\n",
        "    # Original dataset training performance\n",
        "    print('{}{}{}'.format('\\033[1m', 'Original Dataset Training:\\n', '\\033[0m'))\n",
        "    test_model(test_ds, base_model_path+model+'/Original Training')\n",
        "    # Augmented dataset training perforamnce\n",
        "    print('{}{}{}'.format('\\033[1m', 'Augmented Dataset Training:\\n', '\\033[0m'))\n",
        "    test_model(test_ds, base_model_path+model+'/Augmented Training')"
      ],
      "metadata": {
        "id": "3BcNZ88uZgSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d98658e-d5be-4fef-e30d-535a2cb0760a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 346 files belonging to 8 classes.\n",
            "\n",
            "# ---------------------------------------- VGG-16 ---------------------------------------- #\n",
            "\n",
            "\u001b[1mOriginal Dataset Training\u001b[0m\n",
            "Model: vgg16-original-01-0.6029.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation and Preprocessing"
      ],
      "metadata": {
        "id": "Z17a00QembaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Augmentor"
      ],
      "metadata": {
        "id": "d2COUrNmspTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Dataset Split and Preprocessing: 70:20:10 (training, validation, testing) split*"
      ],
      "metadata": {
        "id": "G9yVAClFUxpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import directory navigation libraries and image resizing\n",
        "from os import listdir\n",
        "from shutil import move\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.io import decode_jpeg, encode_jpeg, write_file\n",
        "from tensorflow.dtypes import saturate_cast\n",
        "\n",
        "# Constant values\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/'\n",
        "base_validation_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset/'\n",
        "base_test_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Testing Dataset/'\n",
        "base_original_training_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset/'\n",
        "labels = ['Glass', 'Plastic', 'Paper', 'Metal', 'Cardboard', 'Vegetation', 'Food', 'Trash']\n",
        "\n",
        "# ------------------------------- Functions -------------------------------- #\n",
        "# Resize images\n",
        "def resize_image(path, img_width, img_height):\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        image = open(path+'/'+file, 'rb') # Open image as binary file\n",
        "        binary_representation = image.read() # Read binary file\n",
        "        decoded_representation = decode_jpeg(binary_representation) # Decode image\n",
        "        resized_image = resize(decoded_representation, [img_width, img_height])\n",
        "        resized_image = saturate_cast(resized_image, 'uint8')\n",
        "        encoded_image = encode_jpeg(resized_image)\n",
        "        write_file(path+'/'+file, encoded_image)\n",
        "\n",
        "# Check images for RGB mode and convert if required\n",
        "def convert_rgb_images(path):\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        img = Image.open(path+'/'+file)\n",
        "        if img.mode != 'RGB':\n",
        "            img.convert('RGB').save(path+'/'+file)\n",
        "        \n",
        "# Count number of files in directory\n",
        "def count_files(inputPath, label):\n",
        "    directory = listdir(inputPath+label)\n",
        "    num_files = 0\n",
        "    for file in directory:\n",
        "        num_files += 1\n",
        "    return num_files\n",
        "\n",
        "# Split training and testing dataset\n",
        "def split_dataset(input_path, train_path, val_path, test_path, val_prop, test_prop, label):\n",
        "    # Count images in directory and get files names\n",
        "    num_files = count_files(input_path, label)\n",
        "    file_names = listdir(input_path+label)\n",
        "\n",
        "    # Calculated number of validation and testing images\n",
        "    num_val = round(num_files*val_prop)\n",
        "    num_test = round(num_files*test_prop)\n",
        "    \n",
        "    # Initialise empty lists for validation and testing image indexes\n",
        "    val_list = []\n",
        "    test_list = []\n",
        "    \n",
        "    # Randomly assign file indexes for validation dataset\n",
        "    i = 0\n",
        "    while i < num_val:\n",
        "        r = randint(1, num_files - 1)\n",
        "        if r not in val_list:\n",
        "            val_list.append(r)\n",
        "            i += 1\n",
        "    # Move validation dataset files and rename\n",
        "    name_incrementer = 1\n",
        "    for j in val_list:\n",
        "        move(input_path+label+'/'+file_names[j], val_path+label+'/'+label+'_'+str(name_incrementer)+'.jpg')\n",
        "        name_incrementer += 1\n",
        "\n",
        "    # Update number of files and directory for remaining files\n",
        "    num_files = count_files(input_path, label)\n",
        "    remaining_files = listdir(input_path+label)\n",
        "    # Randomly assign file indexes for testing dataset\n",
        "    i = 0\n",
        "    while i < num_test:\n",
        "        r = randint(1, num_files - 1)\n",
        "        if r not in test_list:\n",
        "            test_list.append(r)\n",
        "            i += 1\n",
        "    # Move test dataset files and rename\n",
        "    name_incrementer = 1\n",
        "    for j in test_list:\n",
        "        move(input_path+label+'/'+remaining_files[j], test_path+label+'/'+label+'_'+str(name_incrementer)+'.jpg')\n",
        "        name_incrementer += 1\n",
        "\n",
        "    # Move remaining files into training dataset\n",
        "    training_files = listdir(input_path+label)\n",
        "    name_incrementer = 1\n",
        "    for file in training_files:\n",
        "        move(input_path+label+'/'+file, train_path+label+'/'+label+'_'+str(name_incrementer)+'.jpg')\n",
        "        name_incrementer += 1\n",
        "\n",
        "# Print number of files in label directories\n",
        "def print_num_files(path, label):\n",
        "    directory = listdir(path+label)\n",
        "    counter = 0\n",
        "    for file in directory:\n",
        "        counter += 1\n",
        "    print(\"Number of files in \" + label +':' + str(counter))\n",
        "\n",
        "# ----------------- Split Training and Validation Datasets ----------------- #\n",
        "# Print split label contents\n",
        "print('# --------------- Total Label Counts ---------------- #')\n",
        "# Split labels base off 70:20:10 training split\n",
        "for label in labels:\n",
        "    print_num_files(base_path+'Unsplit Dataset/', label)\n",
        "    split_dataset(base_path+'Unsplit Dataset/', base_original_training_path, base_validation_path, base_test_path, 0.2, 0.1, label)\n",
        "\n",
        "# Print validation counts for each label\n",
        "print('\\n# ---------- Total Validation Label Counts ---------- #')\n",
        "for label in labels:\n",
        "    print_num_files(base_validation_path, label)\n",
        "\n",
        "# Print testing counts for each label\n",
        "print('\\n# ------------ Total Testing Label Counts ----------- #')\n",
        "for label in labels:\n",
        "    print_num_files(base_test_path, label)\n",
        "\n",
        "# Print training counts for each label in training dataset\n",
        "print('\\n# ----------- Total Training Label Counts ----------- #')\n",
        "for label in labels:\n",
        "    print_num_files(base_original_training_path, label)\n",
        "\n",
        "# ------------------------- Pre-Process Images -------------------------- #\n",
        "# Pre-process training dataset\n",
        "print('\\n# --------- Pre-Processing Training Dataset --------- #')\n",
        "for label in labels:\n",
        "    convert_rgb_images(base_original_training_path+label)\n",
        "    resize_image(base_original_training_path+label, 224, 224)\n",
        "# Pre-process validation dataset\n",
        "print('\\n# -------- Pre-Processing Validation Dataset -------- #')\n",
        "for label in labels:\n",
        "    convert_rgb_images(base_original_training_path+label)\n",
        "    resize_image(base_validation_path+label, 224, 224)\n",
        "# Pre-process test dataset\n",
        "print('\\n# --------- Pre-Processing Testing Dataset --------- #')\n",
        "for label in labels:\n",
        "    convert_rgb_images(base_original_training_path+label)\n",
        "    resize_image(base_test_path+label, 224, 224)"
      ],
      "metadata": {
        "id": "_jR-D3y89F57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Augementation Set 1: Distort and Flip*"
      ],
      "metadata": {
        "id": "GgyR_bKCOuCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data augmentation functions\n",
        "import Augmentor\n",
        "from os import listdir\n",
        "from time import sleep\n",
        "\n",
        "# Define base path of training dataset\n",
        "base_original_training_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset/'\n",
        "# Define labels\n",
        "#labels = ['Glass', 'Plastic', 'Paper', 'Metal', 'Cardboard', 'Vegetation', 'Food', 'Trash']\n",
        "labels = ['Glass']\n",
        "\n",
        "# Verify augmentation counts and print\n",
        "def count_augmented_and_print(path):\n",
        "    count_augmented = 0\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        count_augmented += 1\n",
        "    print('Processed with '+str(count_augmented)+' image(s) found.\\n')\n",
        "\n",
        "# Geometric augmentation function: distort and flip\n",
        "def distort_and_flip(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.flip_left_right(1)                   # Horizontally flip every image\n",
        "    pipe.random_distortion(1, 5, 5, 4)        # Randomly distort flipped images\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "    count_augmented_and_print(path+'/output') # Print augmented image count to console\n",
        "    sleep(60)                                 # Sleep program while images processing\n",
        "\n",
        "# Perform augmentation\n",
        "for label in labels:\n",
        "    distort_and_flip(base_original_training_path+label)"
      ],
      "metadata": {
        "id": "WR_iz_J4OtDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Augmentation Set 2: Rotate and Shear*"
      ],
      "metadata": {
        "id": "9l2NeImgQjJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data augmentation functions\n",
        "import Augmentor\n",
        "from os import listdir\n",
        "from time import sleep\n",
        "\n",
        "# Define base path of training dataset\n",
        "base_original_training_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset/'\n",
        "# Define labels\n",
        "labels = ['Glass', 'Plastic', 'Paper', 'Metal', 'Cardboard', 'Vegetation', 'Food', 'Trash']\n",
        "\n",
        "# Verify augmentation counts and print\n",
        "def count_augmented_and_print(path):\n",
        "    count_augmented = 0\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        count_augmented += 1\n",
        "    print('Processed with '+str(count_augmented)+' image(s) found.\\n')\n",
        "\n",
        "# Geometric augmentation: rotate and shear\n",
        "def rotate_and_shear(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.rotate(1, 25, 25)                    # Rotate every image by 45 degrees\n",
        "    pipe.shear(1, 15, 15)                     # Randomly shear between 0 and 15 degrees\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "    count_augmented_and_print(path+'/output') # Print augmented image count to console\n",
        "    sleep(60)                                 # Sleep program while images processing\n",
        "\n",
        "# Augment images\n",
        "for label in labels:\n",
        "    rotate_and_shear(base_original_training_path+label)"
      ],
      "metadata": {
        "id": "wj0yjMiiQjQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Augmentation Set 3: Random Erasing*"
      ],
      "metadata": {
        "id": "HiBgc25eQjhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data augmentation functions\n",
        "import Augmentor\n",
        "from os import listdir\n",
        "from time import sleep\n",
        "\n",
        "# Define base path of training dataset\n",
        "base_original_training_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset/'\n",
        "# Define labels\n",
        "labels = ['Glass', 'Plastic', 'Paper', 'Metal', 'Cardboard', 'Vegetation', 'Food', 'Trash']\n",
        "\n",
        "# Verify augmentation counts and print\n",
        "def count_augmented_and_print(path):\n",
        "    count_augmented = 0\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        count_augmented += 1\n",
        "    print('Processed with '+str(count_augmented)+' image(s) found.\\n')\n",
        "\n",
        "# Random occlusion: random erasing \n",
        "def random_erase(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.random_erasing(1, 0.15)              # Randomly erase area in every image\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "    count_augmented_and_print(path+'/output') # Print augmented image count to console\n",
        "    sleep(60)                                 # Sleep program while images processing\n",
        "\n",
        "# Augment images\n",
        "for label in labels:\n",
        "    random_erase(base_original_training_path+label)\n",
        "\n",
        "# Second augmentation\n",
        "for label in labels:\n",
        "    random_erase(base_original_training_path+label+'/output')"
      ],
      "metadata": {
        "id": "AvgK26ktQjoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Rename Files*"
      ],
      "metadata": {
        "id": "lVUDecD6ukHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from os import listdir\n",
        "from shutil import move\n",
        "\n",
        "# Constants\n",
        "set_one_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/1 Distort and Flip/'\n",
        "set_two_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/2 Rotate and Shear/'\n",
        "set_three_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/3 Random Erasing/'\n",
        "set_one_augmentation = 'distort_and_flip'\n",
        "set_two_augmentation = 'shear_and_rotate'\n",
        "set_three_augmentation = 'random_erase'\n",
        "labels = ['Glass', 'Plastic', 'Paper', 'Metal', 'Cardboard', 'Vegetation', 'Food', 'Trash']\n",
        "\n",
        "# Get files in directory and rename\n",
        "def rename_files(path, base_name, augmentation):\n",
        "    name_incrementer = 1\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        move(path+'/'+file, path+'/'+base_name+'_'+augmentation+'_'+str(name_incrementer)+'.jpg')\n",
        "        name_incrementer += 1\n",
        "        print(file)\n",
        "    return name_incrementer\n",
        "\n",
        "# Rename files\n",
        "for label in labels:\n",
        "    rename_files(set_one_path+label+'/output', label, set_one_augmentation)\n",
        "    rename_files(set_two_path+label+'/output', label, set_two_augmentation)\n",
        "    rename_files(set_three_path+label+'/output', label, set_three_augmentation)"
      ],
      "metadata": {
        "id": "3M7P4vonum1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*File Counts*"
      ],
      "metadata": {
        "id": "yhoBeSzIB3HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import file navigation library\n",
        "from os import listdir\n",
        "\n",
        "# Directory paths\n",
        "base_validation_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Validation Dataset/'\n",
        "base_test_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Testing Dataset/'\n",
        "base_original_training_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Original Training Dataset/'\n",
        "base_augmented_training_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Augmented Training Dataset/'\n",
        "\n",
        "# Print number of files in label directories\n",
        "def print_num_files(path, label):\n",
        "    directory = listdir(path+label)\n",
        "    counter = 0\n",
        "    for file in directory:\n",
        "        counter += 1\n",
        "    print(\"Number of files in \" + label +':' + str(counter))\n",
        "\n",
        "# Print training counts for each label in training dataset\n",
        "print('\\n# ----------- Total Training Label Counts ----------- #')\n",
        "for label in labels:\n",
        "    print_num_files(base_original_training_path, label)\n",
        "\n",
        "# Print validation counts for each label\n",
        "print('\\n# ---------- Total Validation Label Counts ---------- #')\n",
        "for label in labels:\n",
        "    print_num_files(base_validation_path, label)\n",
        "\n",
        "# Print testing counts for each label\n",
        "print('\\n# ------------ Total Testing Label Counts ----------- #')\n",
        "for label in labels:\n",
        "    print_num_files(base_test_path, label)\n",
        "\n",
        "# Print training counts for each label in training dataset\n",
        "print('\\n# ----------- Total Training Label Counts ----------- #')\n",
        "for label in labels:\n",
        "    print_num_files(base_original_training_path, label)\n",
        "\n",
        "# Print augmented counts for each label in augmented training dataset\n",
        "print('\\n# ----------- Total Augmented Label Counts ----------- #')\n",
        "for label in labels:\n",
        "    print_num_files(base_original_training_path, label)"
      ],
      "metadata": {
        "id": "4iqFvvDOB2dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data augmentation functions\n",
        "import Augmentor\n",
        "\n",
        "# Define path of sample image for each augmentation\n",
        "base_path_set_one = '/content/drive/MyDrive/Colab Notebooks/Data Augmentation Samples/1 Distort and Flip'\n",
        "base_path_set_two = '/content/drive/MyDrive/Colab Notebooks/Data Augmentation Samples/2 Rotate and Shear'\n",
        "base_path_set_three = '/content/drive/MyDrive/Colab Notebooks/Data Augmentation Samples/3 Random Erasing'\n",
        "\n",
        "# Geometric augmentation function: distort and flip\n",
        "def distort_and_flip(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.flip_left_right(1)                   # Horizontally flip every image\n",
        "    pipe.random_distortion(1, 5, 5, 4)        # Randomly distort flipped images\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "\n",
        "# Geometric augmentation: rotate and shear\n",
        "def rotate_and_shear(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.rotate(1, 25, 25)                    # Rotate every image by 45 degrees\n",
        "    pipe.shear(1, 15, 15)                     # Randomly shear between 0 and 15 degrees\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "\n",
        "# Random occlusion: random erasing \n",
        "def random_erase(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.random_erasing(1, 0.15)              # Randomly erase area in every image\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "\n",
        "# Perform augmentations\n",
        "# Distort and flip\n",
        "distort_and_flip(base_path_set_one)\n",
        "# Rotate and shear\n",
        "rotate_and_shear(base_path_set_two)\n",
        "# Random erase\n",
        "random_erase(base_path_set_three)\n",
        "random_erase(base_path_set_three+'/output')"
      ],
      "metadata": {
        "id": "Ml6Fg1d_eI1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Results Processing"
      ],
      "metadata": {
        "id": "HuAhTbKYCyI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import file navigation libraries and file writing\n",
        "from os import listdir\n",
        "import csv\n",
        "\n",
        "# Constants for model file paths\n",
        "base_model_path = '/content/drive/MyDrive/Colab Notebooks/Model Training and Evaluation/Models/'\n",
        "raw_performance_directory = '/Performance/Raw/'\n",
        "curated_performance_directory = '/Performance/Curated/'\n",
        "models = ['VGG-16', 'ResNet-50', 'DenseNet121', 'InceptionV3', 'MobileNetV2']\n",
        "# Constants for epochs to loop over\n",
        "epochs = 200\n",
        "# Field headers\n",
        "field_headers = ['Epoch', 'TrainLoss', 'TrainAccuracy', 'TrainPrecision', 'TrainRecall', 'ValLoss', 'ValAccuracy', 'ValPrecision', 'ValRecall']\n",
        "\n",
        "# Write to files\n",
        "def write_files(base_path, raw_directory, curated_directory, model, epochs, fields):\n",
        "    # Get files in directory\n",
        "    directory = listdir(base_path+model+raw_directory)\n",
        "    for file in directory:\n",
        "        # Open raw txt file\n",
        "        raw = open(base_path+model+raw_directory+file, 'r')\n",
        "        # Parse csv file name\n",
        "        curated_name = file.split('.')[0] + '.csv'\n",
        "        # Open curated csv file\n",
        "        with open(base_path+model+curated_directory+curated_name, 'r+') as csv_file:\n",
        "            # Create csv writer instance\n",
        "            csv_writer = csv.writer(csv_file)\n",
        "            \n",
        "            # Write header rows to csv\n",
        "            csv_writer.writerow(fields)\n",
        "\n",
        "            # Parse results from txt and write to csv\n",
        "            i = 1\n",
        "            counter = 1\n",
        "            for line in raw:\n",
        "                if line[0:5] != 'Epoch' and i in range(6, (epochs*2)+6):\n",
        "                    # Parse out results from lines in txt file\n",
        "                    line = line.split(' - ')\n",
        "                    train_loss = line[2].split(': ')[1]\n",
        "                    train_accuracy = line[3].split(': ')[1]\n",
        "                    train_precision = line[4].split(': ')[1]\n",
        "                    train_recall = line[5].split(': ')[1]\n",
        "                    val_loss = line[6].split(': ')[1]\n",
        "                    val_accuracy = line[7].split(': ')[1]\n",
        "                    val_precision = line[8].split(': ')[1]\n",
        "                    val_recall = line[9].split(': ')[1].replace('\\n', '')\n",
        "                    # Parse results into csv format and write line to file\n",
        "                    line = [counter, train_loss, train_accuracy, train_precision, train_recall, val_loss, val_accuracy, val_precision, val_recall]\n",
        "                    csv_writer.writerow(line)\n",
        "                    counter += 1\n",
        "                i += 1\n",
        "        raw.close()\n",
        "        print('Finished writing to file: '+curated_name)\n",
        "\n",
        "# Loop through folders and parse results into csv\n",
        "for model in models:\n",
        "    write_files(base_model_path, raw_performance_directory, curated_performance_directory, model, epochs, field_headers)"
      ],
      "metadata": {
        "id": "Ygn1jSN0C29K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}